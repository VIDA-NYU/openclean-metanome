{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run HyFD Algorithm - Example\n",
    "\n",
    "This notebook shows an example for running the functional dependency discovery algorithm HyFD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Socrata dataset as the example input.\n",
    "\n",
    "from openclean.data.source.socrata import Socrata\n",
    "df = Socrata().dataset('bre9-aqqr').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Report Date</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Locality</th>\n",
       "      <th>VDH Health District</th>\n",
       "      <th>Total Cases</th>\n",
       "      <th>Hospitalizations</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/28/2020</td>\n",
       "      <td>51001</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Eastern Shore</td>\n",
       "      <td>1340</td>\n",
       "      <td>107</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/28/2020</td>\n",
       "      <td>51003</td>\n",
       "      <td>Albemarle</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>1896</td>\n",
       "      <td>100</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/28/2020</td>\n",
       "      <td>51005</td>\n",
       "      <td>Alleghany</td>\n",
       "      <td>Alleghany</td>\n",
       "      <td>316</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/28/2020</td>\n",
       "      <td>51007</td>\n",
       "      <td>Amelia</td>\n",
       "      <td>Piedmont</td>\n",
       "      <td>210</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/28/2020</td>\n",
       "      <td>51009</td>\n",
       "      <td>Amherst</td>\n",
       "      <td>Central Virginia</td>\n",
       "      <td>810</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60510</th>\n",
       "      <td>06/14/2021</td>\n",
       "      <td>51800</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Western Tidewater</td>\n",
       "      <td>7997</td>\n",
       "      <td>460</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60511</th>\n",
       "      <td>06/14/2021</td>\n",
       "      <td>51810</td>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>36278</td>\n",
       "      <td>1700</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60512</th>\n",
       "      <td>06/14/2021</td>\n",
       "      <td>51820</td>\n",
       "      <td>Waynesboro</td>\n",
       "      <td>Central Shenandoah</td>\n",
       "      <td>2395</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60513</th>\n",
       "      <td>06/14/2021</td>\n",
       "      <td>51830</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>Peninsula</td>\n",
       "      <td>769</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60514</th>\n",
       "      <td>06/14/2021</td>\n",
       "      <td>51840</td>\n",
       "      <td>Winchester</td>\n",
       "      <td>Lord Fairfax</td>\n",
       "      <td>2936</td>\n",
       "      <td>126</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60515 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Report Date   FIPS        Locality VDH Health District  Total Cases  \\\n",
       "0      11/28/2020  51001        Accomack       Eastern Shore         1340   \n",
       "1      11/28/2020  51003       Albemarle    Thomas Jefferson         1896   \n",
       "2      11/28/2020  51005       Alleghany           Alleghany          316   \n",
       "3      11/28/2020  51007          Amelia            Piedmont          210   \n",
       "4      11/28/2020  51009         Amherst    Central Virginia          810   \n",
       "...           ...    ...             ...                 ...          ...   \n",
       "60510  06/14/2021  51800         Suffolk   Western Tidewater         7997   \n",
       "60511  06/14/2021  51810  Virginia Beach      Virginia Beach        36278   \n",
       "60512  06/14/2021  51820      Waynesboro  Central Shenandoah         2395   \n",
       "60513  06/14/2021  51830    Williamsburg           Peninsula          769   \n",
       "60514  06/14/2021  51840      Winchester        Lord Fairfax         2936   \n",
       "\n",
       "       Hospitalizations  Deaths  \n",
       "0                   107      21  \n",
       "1                   100      27  \n",
       "2                    19       7  \n",
       "3                    21       6  \n",
       "4                    31       6  \n",
       "...                 ...     ...  \n",
       "60510               460     191  \n",
       "60511              1700     412  \n",
       "60512                73      38  \n",
       "60513                29      13  \n",
       "60514               126      47  \n",
       "\n",
       "[60515 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run using local Java JRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download jar file as /home/heiko/.cache/openclean_metanome/Metanome.jar\n",
      "file exists\n"
     ]
    }
   ],
   "source": [
    "# Download the 'Metanome.jar' file if no copy exists on the\n",
    "# local machine at the path that is defined by config.JARFILE().\n",
    "\n",
    "from openclean_metanome.download import download_jar\n",
    "\n",
    "download_jar(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metanome Data Profiling Wrapper - Version 0.1.0\n",
      "\n",
      "Initializing ...\n",
      "Reading data and calculating plis ...\n",
      "Sorting plis by number of clusters ...\n",
      "Inverting plis ...\n",
      "Extracting integer representations for the records ...\n",
      "Investigating comparison suggestions ... \n",
      "Sorting clusters ...(127ms)\n",
      "Running initial windows ...(158ms)\n",
      "Moving window over clusters ... \n",
      "Window signature: [2][2][1][1][1][1][1]\n",
      "Inducing FD candidates ...\n",
      "Validating FDs using plis ...\n",
      "\tLevel 0: 1 elements; (V)(C)(G); 0 intersections; 0 validations; 0 invalid; 0 new candidates; --> 0 FDs\n",
      "\tLevel 1: 6 elements; (V)(C)(G); 2 intersections; 2 validations; 0 invalid; 0 new candidates; --> 2 FDs\n",
      "\tLevel 2: 9 elements; (V)(C)(G); 4 intersections; 16 validations; 6 invalid; 4 new candidates; --> 10 FDs\n",
      "Investigating comparison suggestions ... \n",
      "Moving window over clusters ... \n",
      "Window signature: [2][2][2][1][1][1][1]\n",
      "Inducing FD candidates ...\n",
      "Validating FDs using plis ...\n",
      "\tLevel 3: 10 elements; (V)(-)(-); 10 intersections; 26 validations; 26 invalid; - new candidates; --> 0 FDs\n",
      "Translating FD-tree into result format ...\n",
      "... done! (12 FDs)\n",
      "Time: 816 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the HyFD algorithm on the downloaded dataset.\n",
    "\n",
    "from openclean_metanome.algorithm.hyfd import hyfd\n",
    "\n",
    "fds = hyfd(df, max_lhs_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIPS,Total Cases] -> [VDH Health District]\n",
      "[Locality,Total Cases] -> [VDH Health District]\n",
      "[Report Date,FIPS] -> [Total Cases]\n",
      "[Report Date,FIPS] -> [Hospitalizations]\n",
      "[Report Date,FIPS] -> [Deaths]\n",
      "[Report Date,FIPS] -> [VDH Health District]\n",
      "[Report Date,Locality] -> [Total Cases]\n",
      "[Report Date,Locality] -> [Hospitalizations]\n",
      "[Report Date,Locality] -> [Deaths]\n",
      "[Report Date,Locality] -> [VDH Health District]\n",
      "[FIPS] -> [Locality]\n",
      "[Locality] -> [FIPS]\n"
     ]
    }
   ],
   "source": [
    "# Print discovered functional dependencies.\n",
    "\n",
    "for fd in fds:\n",
    "    print(str(fd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run using local Docker instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METANOME_WORKER=None\n",
      "METANOME_CONTAINER=heikomueller/openclean-metanome:0.1.0\n",
      "METANOME_JARPATH=/home/heiko/.cache/openclean_metanome/Metanome.jar\n"
     ]
    }
   ],
   "source": [
    "# When running HyFD using Docker, the worker that executes the HyFD\n",
    "# algorithm, the image identifier for the Docker container, and the\n",
    "# name of the JAR file in the container need to be specified via the\n",
    "# environment variables 'METANOME_WORKER', METANOME_CONTAINER' and\n",
    "# 'METANOME_JARPATH'. The current values for these three variables\n",
    "# can be accessed using the configuration helper functions WORKER,\n",
    "# CONTAINER and JARFILE. These functions will return the default\n",
    "# values if the environment variables are not set.\n",
    "\n",
    "from openclean_metanome import config\n",
    "\n",
    "print(f'{config.METANOME_WORKER}={config.WORKER()}')\n",
    "print(f'{config.METANOME_CONTAINER}={config.CONTAINER()}')\n",
    "print(f'{config.METANOME_JARPATH}={config.JARFILE()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METANOME_WORKER={'name': '2b847d0399424550841bc3d847154b7e', 'type': 'docker', 'env': [], 'variables': []}\n",
      "METANOME_CONTAINER=heikomueller/openclean-metanome:0.1.0\n",
      "METANOME_JARPATH=lib/Metanome.jar\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters can also be set using a dictionary that\n",
    "# is passed to the hyfd method. For example, when running HyFD using\n",
    "# default container image 'heikomueller/openclean-metanome:0.1.0' the\n",
    "# Jar-file path needs to be set to 'lib/Metanome.jar'.\n",
    "# The Docker() helper function is used to set the worker to be a Docker\n",
    "# worker.\n",
    "\n",
    "from openclean_metanome.config import Docker\n",
    "\n",
    "env = {\n",
    "    config.METANOME_WORKER: Docker(),\n",
    "    config.METANOME_CONTAINER: 'heikomueller/openclean-metanome:0.1.0',\n",
    "    config.METANOME_JARPATH: 'lib/Metanome.jar'\n",
    "}\n",
    "\n",
    "print(f'{config.METANOME_WORKER}={config.WORKER(env=env)}')\n",
    "print(f'{config.METANOME_CONTAINER}={config.CONTAINER(env=env)}')\n",
    "print(f'{config.METANOME_JARPATH}={config.JARFILE(env=env)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metanome Data Profiling Wrapper - Version 0.1.0\n",
      "\n",
      "Initializing ...\n",
      "Reading data and calculating plis ...\n",
      "Sorting plis by number of clusters ...\n",
      "Inverting plis ...\n",
      "Extracting integer representations for the records ...\n",
      "Investigating comparison suggestions ... \n",
      "Sorting clusters ...(114ms)\n",
      "Running initial windows ...(166ms)\n",
      "Moving window over clusters ... \n",
      "Window signature: [2][2][1][1][1][1][1]\n",
      "Inducing FD candidates ...\n",
      "Validating FDs using plis ...\n",
      "\tLevel 0: 1 elements; (V)(C)(G); 0 intersections; 0 validations; 0 invalid; 0 new candidates; --> 0 FDs\n",
      "\tLevel 1: 6 elements; (V)(C)(G); 2 intersections; 2 validations; 0 invalid; 0 new candidates; --> 2 FDs\n",
      "\tLevel 2: 9 elements; (V)(C)(G); 4 intersections; 16 validations; 6 invalid; 4 new candidates; --> 10 FDs\n",
      "Investigating comparison suggestions ... \n",
      "Moving window over clusters ... \n",
      "Window signature: [2][2][2][1][1][1][1]\n",
      "Inducing FD candidates ...\n",
      "Validating FDs using plis ...\n",
      "\tLevel 3: 10 elements; (V)(-)(-); 10 intersections; 26 validations; 26 invalid; - new candidates; --> 0 FDs\n",
      "Translating FD-tree into result format ...\n",
      "... done! (12 FDs)\n",
      "Time: 923 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the HyFD algorithm on the downloaded dataset using the\n",
    "# default environment settings for Docker workers.\n",
    "\n",
    "from openclean_metanome.algorithm.hyfd import hyfd\n",
    "\n",
    "fds = hyfd(df, max_lhs_size=3, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FIPS,Total Cases] -> [VDH Health District]\n",
      "[Locality,Total Cases] -> [VDH Health District]\n",
      "[Report Date,FIPS] -> [Total Cases]\n",
      "[Report Date,FIPS] -> [Hospitalizations]\n",
      "[Report Date,FIPS] -> [Deaths]\n",
      "[Report Date,FIPS] -> [VDH Health District]\n",
      "[Report Date,Locality] -> [Total Cases]\n",
      "[Report Date,Locality] -> [Hospitalizations]\n",
      "[Report Date,Locality] -> [Deaths]\n",
      "[Report Date,Locality] -> [VDH Health District]\n",
      "[FIPS] -> [Locality]\n",
      "[Locality] -> [FIPS]\n"
     ]
    }
   ],
   "source": [
    "# Print discovered functional dependencies.\n",
    "\n",
    "for fd in fds:\n",
    "    print(str(fd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
